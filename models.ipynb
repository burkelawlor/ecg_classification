{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6850345-c133-456a-90c7-b032cc2cf35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec27688-51ce-46cd-986f-f17abd60e964",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Quetsions to ask:\n",
    "\n",
    "- What does 1d vs 2 architecture actually mean?\n",
    "- What model does he think is the best?\n",
    "- Visualization? Attribution map? 1d version of saliecy\n",
    "\n",
    "- Sliding window approach -> predict on segmets and take element wise maximum to produce single prediction for whole sample (window wize 2.5 second)\n",
    "- element wise maximum for test set? or is that included in the training?\n",
    "- preprocessing\n",
    "\n",
    "\n",
    "- map signal into a frequency domain\n",
    "decompose waveform into frequency componenets, comination of sin waves with differenct frequencies -> spectrogram time vs frequency vs color\n",
    "makes it a 2d problem\n",
    "spectrogram is already in scipy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8816052e-ce7b-44b0-8e55-1616aa84d8cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4020b187-3558-4d98-8fd6-e842b3cc4e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from cleaned pickles\n",
    "database = pd.read_pickle('data/database.pkl')\n",
    "ecg_data = pd.read_pickle('data/ecg_data.pkl')\n",
    "\n",
    "X = np.array(ecg_data)\n",
    "Y = np.array(database['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0293b05f-fd68-427a-9b74-3ab423c44809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data from folds provided by ptb xl\n",
    "val_fold  = [8,9]\n",
    "test_fold = [10] \n",
    "\n",
    "train_idx = np.where(np.isin(database['strat_fold'], [1,2,3], invert=True))\n",
    "# train_idx = np.where(np.isin(database['strat_fold'], val_fold+test_fold, invert=True))\n",
    "val_idx = np.where(np.isin(database['strat_fold'], val_fold))\n",
    "test_idx = np.where(np.isin(database['strat_fold'], test_fold))\n",
    "\n",
    "X_train = list(X[train_idx])\n",
    "X_val   = list(X[val_idx])\n",
    "X_test  = list(X[test_idx])\n",
    "Y_train = list(Y[train_idx])\n",
    "Y_val   = list(Y[val_idx])\n",
    "Y_test  = list(Y[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e0f095-2ec1-4e7a-b7fa-ac17fa59a13f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "# val_dataset   = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "# test_dataset  = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5792872b-4aed-40f1-b802-220491686686",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The dataset length is unknown.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_42640/554757276.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mSHUFFLE_BUFFER_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSHUFFLE_BUFFER_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    516\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The dataset is infinite.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mUNKNOWN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The dataset length is unknown.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The dataset length is unknown."
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = len(X_train)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "beccc930-bfef-45c5-85d0-38a85f3b2713",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes = 23\n",
      "input_shape = (12, 1000)\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(Y))\n",
    "input_shape = X[0].shape\n",
    "\n",
    "print('num_classes =', num_classes)\n",
    "print('input_shape =', input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc8889-f4c6-43d3-96d9-4c7997d6e6b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "02fd7337-4561-44a5-980b-2a394a429f16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 250)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sliding_window(data_label_tuple, sequence_length=250, sequence_stride=50):\n",
    "    '''\n",
    "    Creates a nested tuple ((array,label),(array,label)) length sequence_length\n",
    "    and stride sequence_stride from original array in data_label_tuple.\n",
    "    \n",
    "    ***Shape must match***\n",
    "    \n",
    "    INPUTS:\n",
    "        data_label_tuple: tuple of length 2, (original_array, label)\n",
    "        sequence length: length of resulting sequences\n",
    "        sequence stride: stride between initial index of sequences\n",
    "        \n",
    "    outputs:\n",
    "        nested tuple of form ((array, label),(array,label))\n",
    "    array data\n",
    "    '''\n",
    "    \n",
    "    sequence = data_label_tuple[0]\n",
    "    label = data_label_tuple[1]\n",
    "    n_sequences = int((sequence.shape[1]-sequence_length)/sequence_stride)\n",
    "    \n",
    "    start_idx = 0\n",
    "    seq_labels = ()\n",
    "    for i in range(n_sequences):\n",
    "        seq = sequence[:,start_idx:start_idx+sequence_length]\n",
    "        start_idx += sequence_stride\n",
    "        seq_labels += ((seq,label),)\n",
    "    \n",
    "    return seq_labels\n",
    "\n",
    "\n",
    "for elem in train_dataset.take(1).as_numpy_iterator():\n",
    "    input_tuple = elem\n",
    "sequence_length = 250\n",
    "sequence_stride = 50\n",
    "\n",
    "temp = sliding_window(input_tuple, sequence_length, sequence_stride)\n",
    "temp[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ff2435c-103d-4ce7-9c40-1883e0a99ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sliding_window(array, label, sequence_length=250, sequence_stride=50):\n",
    "    '''\n",
    "    Creates a tuple of arrays of length sequence_length and stride sequence_stride. \n",
    "    \n",
    "    INPUTS:\n",
    "        array: numpy array of 1d or 2d sequential data\n",
    "        sequence length: length of resulting sequences\n",
    "        sequence stride: stride between initial index of sequences\n",
    "        \n",
    "    OUTPUTS:\n",
    "        tuple of arrays\n",
    "    '''\n",
    "    n_sequences = int((array.shape[1]-sequence_length)/sequence_stride)\n",
    "    labels = [label]*n_sequences\n",
    "    \n",
    "    start_idx = 0\n",
    "    seqs = []\n",
    "    for i in range(n_sequences):\n",
    "        seq = array[:,start_idx:start_idx+sequence_length]\n",
    "        start_idx += sequence_stride\n",
    "        seqs.append(seq)\n",
    "    \n",
    "    return seqs, labels\n",
    "\n",
    "def apply_sliding_window(X, Y, sequence_length=250, sequence_stride=50):\n",
    "    '''\n",
    "    Applies sliding window to a list of arrays\n",
    "    '''\n",
    "    X_windows = []\n",
    "    Y_windows = []\n",
    "    for i in range(len(X)):\n",
    "        seqs, labels = sliding_window(X[i], Y[i], sequence_length, sequence_stride)\n",
    "        X_windows += seqs \n",
    "        Y_windows += labels\n",
    "    return X_windows, Y_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "655a79c2-1935-4206-8f6e-7a789c6d3ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 250\n",
    "sequence_stride = 50\n",
    "\n",
    "X_train_windows, Y_train_windows = apply_sliding_window(X_train, Y_train, sequence_length, sequence_stride)\n",
    "X_val_windows, Y_val_windows = apply_sliding_window(X_val, Y_val, sequence_length, sequence_stride)\n",
    "X_test_windows, Y_test_windows = apply_sliding_window(X_test, Y_test, sequence_length, sequence_stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "39352851-f750-4bd5-ab76-d03442dd54ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Serialize ecg data\n",
    "record_file = 'X_train.tfrecord'\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    for i in range(len(X_train_windows)):\n",
    "        serialized_ecg = tf.io.serialize_tensor(X_train_windows[i])\n",
    "        writer.write(serialized_ecg.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c1b0ed3-a521-45ef-b848-46932276a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "parse_tensor = lambda x: tf.io.parse_tensor(x, tf.double)\n",
    "X_train = (tf.data.TFRecordDataset('X_train.tfrecord').map(parse_tensor))\n",
    "X_train = X_train.map(lambda x: tf.reshape(x, [12,250]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a33b9157-14b0-40db-80da-6ae0944fa266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize labels\n",
    "record_file = 'Y_train.tfrecord'\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    for i in range(len(Y_train_windows)):\n",
    "        serialized_label = tf.io.serialize_tensor(Y_train_windows[i])\n",
    "        writer.write(serialized_label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb0da4b7-b9f6-404a-baaf-86fce230cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "parse_labels = lambda x: tf.io.parse_tensor(x, tf.int64)\n",
    "Y_train = (tf.data.TFRecordDataset('Y_train.tfrecord').map(parse_labels))\n",
    "Y_train = Y_train.map(lambda x: tf.reshape(x, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fd8702e-c121-4f5b-8a6f-f8b04fb35cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "SHUFFLE_BUFFER_SIZE = len(X_train_windows)\n",
    "\n",
    "train_ds = tf.data.Dataset.zip((X_train, Y_train))\n",
    "train_ds = train_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "# print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5232a22-eddf-48b7-af31-7e3026851a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data, label in train_ds.take(1).as_numpy_iterator():\n",
    "#     x = data \n",
    "#     print(x)\n",
    "#     y = label\n",
    "#     print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2eb3bf56-15e3-4301-a2f5-d9bd779a5f87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes = 23\n",
      "input_shape = (12, 250)\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(Y))\n",
    "input_shape = X_train_windows[0].shape\n",
    "\n",
    "print('num_classes =', num_classes)\n",
    "print('input_shape =', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c9039d-e25b-4d60-b9d6-e0861cb7766d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_example(height, width, image_raw, label):\n",
    "    image_data = tf.io.decode_raw(image_raw, tf.uint8)\n",
    "    image_data = tf.reshape(image_data, [1, height, width])\n",
    "    return image_data, label\n",
    "\n",
    "def make_dataset(partition):\n",
    "    # dataset = dataset.shuffle(buffer_size=FLAGS.shuffle_buffer_size)\n",
    "    dataset = dataset.map(decode_example)\n",
    "    dataset = dataset.map(\n",
    "        lambda x: map_example(x['height'], x['width'], x['image_raw'], x['label']))\n",
    "    # dataset = dataset.batch(batch_size=FLAGS.batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2309b4ea-9602-4260-865b-124adcf79eaf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_windows = [X_test_windows,Y_test_windows]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e798f9-cd2c-43ab-85aa-33e98f403a27",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "tf records, save everythign into harddrive first\n",
    "dump everythign into tf record file, each sample becomes a tf record (sits on hard drive)\n",
    "create a tf record dataset, tf has pointers to the HDD to pull up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "79c9a214-cb59-42d7-9452-1bc2d09e706b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save file as pickle\n",
    "with open('data/test.pkl', 'wb') as f:\n",
    "    pickle.dump(X_test_windows, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9cc2e688-9a97-44c1-bc01-2c99243e5de8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load pickle\n",
    "with open('data/test.pkl', 'rb') as f:\n",
    "    mynewlist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6c3c4bab-6053-4ce6-9184-963f04b16ae1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_to_multiple_pickles(data, name_prefix, n_parts=10):\n",
    "    data_dir = 'data'\n",
    "    path_format = os.path.join(data_dir, \"{}_{:02d}.pkl\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    temp = list(enumerate(np.array_split(np.arange(m), n_parts)))\n",
    "    \n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_pkl = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_pkl)\n",
    "        with open(part_pkl, 'wb') as f:\n",
    "            pickle.dump([data[i] for i in row_indices], f)\n",
    "\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3a89c5bb-eecd-4d4e-96c4-f3117a60a148",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_filepaths = save_to_multiple_pickles(X_train_windows, 'X_train', n_parts=10)\n",
    "Y_train_filepaths = save_to_multiple_pickles(Y_train_windows, 'Y_train', n_parts=10)\n",
    "X_val_filepaths = save_to_multiple_pickles(X_val_windows, 'X_val', n_parts=4)\n",
    "Y_val_filepaths = save_to_multiple_pickles(Y_val_windows, 'Y_val', n_parts=4)\n",
    "X_test_filepaths = save_to_multiple_pickles(X_test_windows, 'X_test', n_parts=2)\n",
    "Y_test_filepaths = save_to_multiple_pickles(Y_test_windows, 'Y_test', n_parts=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "80d64501-8e90-4660-a3cd-41fef98c721a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load pickle\n",
    "with open(X_train_filepaths[0], 'rb') as f:\n",
    "    mynewlist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7bd7a-8991-4acc-9f48-451fef4bb1ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "28687a20-ef3c-424a-8fd8-3ce4de7d19e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath_dataset = tf.data.Dataset.list_files(X_train_filepaths, seed=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e24ced00-0f66-4f04-851b-747e4a5bd208",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'data\\\\X_train_06.pkl', shape=(), dtype=string)\n",
      "tf.Tensor(b'data\\\\X_train_04.pkl', shape=(), dtype=string)\n",
      "tf.Tensor(b'data\\\\X_train_01.pkl', shape=(), dtype=string)\n",
      "tf.Tensor(b'data\\\\X_train_05.pkl', shape=(), dtype=string)\n",
      "tf.Tensor(b'data\\\\X_train_08.pkl', shape=(), dtype=string)\n",
      "tf.Tensor(b'data\\\\X_train_00.pkl', shape=(), dtype=string)\n",
      "tf.Tensor(b'data\\\\X_train_09.pkl', shape=(), dtype=string)\n",
      "tf.Tensor(b'data\\\\X_train_07.pkl', shape=(), dtype=string)\n",
      "tf.Tensor(b'data\\\\X_train_03.pkl', shape=(), dtype=string)\n",
      "tf.Tensor(b'data\\\\X_train_02.pkl', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for filepath in filepath_dataset:\n",
    "    print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "770c25d1-b1c0-4b3f-9542-0d9102a58cd3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_11160/112520393.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_dataset_windows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_windows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_windows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_dataset\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_windows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val_windows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_dataset\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_windows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test_windows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    791\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m     \"\"\"\n\u001b[1;32m--> 793\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m   \u001b[1;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m   4475\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_files\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4476\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4477\u001b[1;33m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4478\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4479\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    123\u001b[0m           \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m           normalized_components.append(\n\u001b[1;32m--> 125\u001b[1;33m               ops.convert_to_tensor(t, name=\"component_%d\" % i, dtype=dtype))\n\u001b[0m\u001b[0;32m    126\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpack_as\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    341\u001b[0m                                          as_ref=False):\n\u001b[0;32m    342\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m--> 267\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    268\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "train_dataset_windows = tf.data.Dataset.from_tensor_slices((X_train_windows, Y_train_windows))\n",
    "val_dataset   = tf.data.Dataset.from_tensor_slices((X_val_windows, Y_val_windows))\n",
    "test_dataset  = tf.data.Dataset.from_tensor_slices((X_test_windows, Y_test_windows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1e8b7-5fd5-428b-8a1b-2c3622c855df",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "SHUFFLE_BUFFER_SIZE = len(X_train)\n",
    "\n",
    "train_dataset_windows = train_dataset_windows.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)#.window(size=250, shift=50)\n",
    "val_dataset_windows = val_dataset_windows.batch(BATCH_SIZE)#.window(size=250, shift=50)\n",
    "test_dataset_windows = test_dataset_windows.batch(1)#.window(size=250, shift=50)\n",
    "\n",
    "input_shape = (12, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e69b129a-bea1-40d3-bb72-05dff3d5186f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[-0.119, -0.116, -0.12 , ..., -0.064, -0.073, -0.093],\n",
      "       [-0.055, -0.051, -0.044, ...,  0.009, -0.007, -0.024],\n",
      "       [ 0.064,  0.065,  0.076, ...,  0.073,  0.065,  0.068],\n",
      "       ...,\n",
      "       [-0.026, -0.031, -0.028, ..., -0.022, -0.025, -0.03 ],\n",
      "       [-0.039, -0.034, -0.029, ..., -0.019, -0.025, -0.035],\n",
      "       [-0.079, -0.074, -0.069, ...,  0.017,  0.015,  0.011]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[ 0.021,  0.011, -0.009, ..., -0.011, -0.033,  0.204],\n",
      "       [ 0.151,  0.137,  0.117, ..., -0.026,  0.014,  0.227],\n",
      "       [ 0.13 ,  0.126,  0.127, ..., -0.014,  0.046,  0.023],\n",
      "       ...,\n",
      "       [ 0.176,  0.171,  0.153, ..., -0.037,  0.023,  0.356],\n",
      "       [ 0.177,  0.16 ,  0.149, ..., -0.044, -0.022,  0.248],\n",
      "       [ 0.114,  0.106,  0.103, ..., -0.017, -0.006,  0.171]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[-0.051, -0.072, -0.098, ..., -0.058, -0.033,  0.021],\n",
      "       [ 0.013,  0.016, -0.023, ...,  0.011,  0.012,  0.057],\n",
      "       [ 0.064,  0.088,  0.075, ...,  0.07 ,  0.045,  0.035],\n",
      "       ...,\n",
      "       [ 0.007,  0.017,  0.012, ..., -0.05 , -0.047, -0.027],\n",
      "       [-0.006,  0.002,  0.005, ..., -0.031, -0.028, -0.022],\n",
      "       [-0.003,  0.008,  0.017, ..., -0.009, -0.002,  0.006]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[-0.091, -0.102, -0.114, ...,  0.027,  0.014, -0.032],\n",
      "       [-0.046, -0.067, -0.065, ...,  0.029,  0.028, -0.018],\n",
      "       [ 0.045,  0.035,  0.049, ...,  0.002,  0.015,  0.013],\n",
      "       ...,\n",
      "       [ 0.014,  0.002, -0.009, ..., -0.122, -0.072, -0.059],\n",
      "       [-0.006, -0.03 , -0.036, ..., -0.065, -0.07 , -0.064],\n",
      "       [ 0.018,  0.008,  0.004, ...,  0.062,  0.02 ,  0.006]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[-0.037, -0.102, -0.077, ...,  0.034, -0.004, -0.042],\n",
      "       [-0.062, -0.072, -0.068, ...,  0.044,  0.016, -0.012],\n",
      "       [-0.025,  0.03 ,  0.008, ...,  0.009,  0.02 ,  0.03 ],\n",
      "       ...,\n",
      "       [-0.014, -0.028, -0.021, ..., -0.024, -0.028, -0.042],\n",
      "       [-0.03 , -0.033, -0.037, ..., -0.014, -0.023, -0.041],\n",
      "       [ 0.005, -0.003, -0.009, ..., -0.055, -0.055, -0.059]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[-0.069, -0.079, -0.094, ..., -0.028,  0.051,  0.   ],\n",
      "       [-0.014, -0.016, -0.023, ..., -0.049,  0.028, -0.012],\n",
      "       [ 0.056,  0.063,  0.071, ..., -0.021, -0.024, -0.012],\n",
      "       ...,\n",
      "       [-0.042, -0.043, -0.035, ..., -0.055, -0.054, -0.047],\n",
      "       [-0.05 , -0.057, -0.05 , ..., -0.067, -0.063, -0.057],\n",
      "       [ 0.01 ,  0.01 ,  0.005, ..., -0.095, -0.092, -0.086]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[ 0.628,  0.45 ,  0.053, ..., -0.013, -0.017, -0.003],\n",
      "       [ 0.423,  0.29 ,  0.029, ..., -0.048, -0.04 , -0.045],\n",
      "       [-0.204, -0.16 , -0.023, ..., -0.035, -0.023, -0.042],\n",
      "       ...,\n",
      "       [ 0.51 ,  0.048, -0.282, ..., -0.05 , -0.05 , -0.05 ],\n",
      "       [ 0.506,  0.322,  0.071, ..., -0.055, -0.055, -0.055],\n",
      "       [ 0.441,  0.444,  0.308, ..., -0.105, -0.105, -0.106]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[ 0.019,  0.019, -0.018, ..., -0.015, -0.028, -0.023],\n",
      "       [ 0.06 ,  0.046,  0.037, ..., -0.06 , -0.052, -0.051],\n",
      "       [ 0.041,  0.027,  0.055, ..., -0.045, -0.024, -0.028],\n",
      "       ...,\n",
      "       [-0.01 , -0.031, -0.035, ..., -0.026, -0.024, -0.018],\n",
      "       [-0.02 , -0.035, -0.038, ..., -0.055, -0.051, -0.044],\n",
      "       [ 0.014,  0.01 ,  0.005, ..., -0.123, -0.115, -0.119]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[-0.051,  0.008, -0.022, ..., -0.032, -0.022, -0.011],\n",
      "       [-0.013,  0.012, -0.024, ..., -0.078, -0.084, -0.069],\n",
      "       [ 0.038,  0.005, -0.002, ..., -0.046, -0.062, -0.058],\n",
      "       ...,\n",
      "       [-0.059, -0.05 , -0.045, ..., -0.032, -0.029, -0.03 ],\n",
      "       [-0.062, -0.057, -0.055, ..., -0.023, -0.03 , -0.049],\n",
      "       [-0.002, -0.009, -0.015, ..., -0.094, -0.097, -0.11 ]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[-0.008,  0.024, -0.003, ...,  0.018,  0.032,  0.037],\n",
      "       [ 0.002,  0.016,  0.005, ..., -0.04 , -0.031, -0.02 ],\n",
      "       [ 0.011, -0.008,  0.008, ..., -0.058, -0.063, -0.057],\n",
      "       ...,\n",
      "       [-0.046, -0.044, -0.046, ...,  0.004,  0.007,  0.015],\n",
      "       [-0.04 , -0.04 , -0.037, ..., -0.022, -0.017, -0.01 ],\n",
      "       [-0.06 , -0.065, -0.071, ..., -0.007,  0.002,  0.029]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[-0.075, -0.034,  0.017, ..., -0.015, -0.004,  0.004],\n",
      "       [-0.059, -0.038, -0.023, ..., -0.078, -0.063, -0.061],\n",
      "       [ 0.016, -0.005, -0.04 , ..., -0.064, -0.059, -0.064],\n",
      "       ...,\n",
      "       [-0.046, -0.051, -0.054, ..., -0.056, -0.071, -0.059],\n",
      "       [-0.054, -0.048, -0.046, ..., -0.039, -0.036, -0.031],\n",
      "       [-0.083, -0.076, -0.078, ..., -0.079, -0.076, -0.071]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[ 0.016, -0.012, -0.026, ...,  0.063,  0.049,  0.128],\n",
      "       [-0.043, -0.063, -0.072, ...,  0.061,  0.057,  0.144],\n",
      "       [-0.059, -0.051, -0.046, ..., -0.002,  0.009,  0.016],\n",
      "       ...,\n",
      "       [-0.05 , -0.06 , -0.066, ...,  0.087,  0.119,  0.151],\n",
      "       [-0.055, -0.062, -0.065, ...,  0.098,  0.126,  0.161],\n",
      "       [-0.11 , -0.11 , -0.11 , ...,  0.03 ,  0.069,  0.118]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[ 0.019,  0.013,  0.003, ..., -0.021, -0.03 ,  0.007],\n",
      "       [-0.044, -0.046, -0.044, ...,  0.01 ,  0.016,  0.051],\n",
      "       [-0.063, -0.059, -0.047, ...,  0.032,  0.046,  0.044],\n",
      "       ...,\n",
      "       [-0.014, -0.023, -0.014, ..., -0.001,  0.003,  0.015],\n",
      "       [-0.038, -0.031, -0.024, ..., -0.032, -0.023, -0.004],\n",
      "       [-0.138, -0.131, -0.119, ..., -0.032,  0.003,  0.043]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[-0.04 , -0.012, -0.004, ...,  0.06 ,  0.044,  0.064],\n",
      "       [-0.062, -0.057, -0.045, ...,  0.06 ,  0.031,  0.045],\n",
      "       [-0.022, -0.046, -0.042, ...,  0.   , -0.013, -0.019],\n",
      "       ...,\n",
      "       [-0.025, -0.025, -0.024, ...,  0.052,  0.008, -0.003],\n",
      "       [-0.046, -0.039, -0.035, ...,  0.047,  0.026,  0.016],\n",
      "       [-0.108, -0.103, -0.101, ...,  0.105,  0.069,  0.053]])>, <tf.Tensor: shape=(12, 250), dtype=float64, numpy=\n",
      "array([[ 0.041,  0.059,  0.084, ...,  0.113,  0.136,  0.184],\n",
      "       [-0.022, -0.001,  0.067, ...,  0.077,  0.063,  0.081],\n",
      "       [-0.063, -0.06 , -0.017, ..., -0.036, -0.073, -0.103],\n",
      "       ...,\n",
      "       [ 0.013,  0.02 ,  0.069, ..., -0.001,  0.006,  0.023],\n",
      "       [-0.005,  0.003,  0.034, ..., -0.009, -0.003,  0.018],\n",
      "       [ 0.054,  0.066,  0.107, ...,  0.028,  0.045,  0.06 ]])>)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[-0.119 -0.116 -0.12  ...  0.069  0.086  0.022]\n",
      " [-0.055 -0.051 -0.044 ...  0.     0.004 -0.031]\n",
      " [ 0.064  0.065  0.076 ... -0.069 -0.081 -0.054]\n",
      " ...\n",
      " [-0.026 -0.031 -0.028 ...  0.024  0.242  0.143]\n",
      " [-0.039 -0.034 -0.029 ... -0.041 -0.046 -0.035]\n",
      " [-0.079 -0.074 -0.069 ... -0.058 -0.098 -0.12 ]], shape=(12, 1000), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "window_ds = train_dataset.map(lambda x, y: (sliding_window(x), y))\n",
    "for x, y in window_ds.take(1):\n",
    "    print(x)\n",
    "    print(y)\n",
    "    \n",
    "for x, y in train_dataset.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b1d2d13a-d144-453a-832f-92b5ab7085e9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_22972/834844556.py\", line 8, in None  *\n        lambda ecg, label: sliding_window(ecg, label)\n    File \"C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_22972/1376489108.py\", line 24, in sliding_window  *\n        for i in range(n_sequences):\n\n    ValueError: Shape must be rank 0 but is rank 1\n    \t for 'limit' for '{{node range}} = Range[Tidx=DT_INT32](range/start, Maximum, range/delta)' with input shapes: [], [?], [].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_22972/2002658056.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     print(elem.map(sliding_window))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtemp_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mecg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msliding_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mecg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# for elem in temp_ds:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#     print(len(elem))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[0;32m   2015\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[1;32m-> 2016\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2017\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5189\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5190\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5191\u001b[1;33m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   5192\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5193\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;31m# There is no graph to add in eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[1;33m&=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3068\u001b[0m          \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3069\u001b[0m     \"\"\"\n\u001b[1;32m-> 3070\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   3071\u001b[0m         *args, **kwargs)\n\u001b[0;32m   3072\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3034\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3035\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3036\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3037\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3038\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3292\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   3294\u001b[0m                                    graph_function)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3128\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3129\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3130\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3131\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3132\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    246\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m    247\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_22972/834844556.py\", line 8, in None  *\n        lambda ecg, label: sliding_window(ecg, label)\n    File \"C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_22972/1376489108.py\", line 24, in sliding_window  *\n        for i in range(n_sequences):\n\n    ValueError: Shape must be rank 0 but is rank 1\n    \t for 'limit' for '{{node range}} = Range[Tidx=DT_INT32](range/start, Maximum, range/delta)' with input shapes: [], [?], [].\n"
     ]
    }
   ],
   "source": [
    "# train_dataset.take(1)\n",
    "# for ecg, label in ds.as_numpy_iterator():\n",
    "#     print(ecg.shape)\n",
    "\n",
    "# for elem in train_dataset.take(1):\n",
    "#     print(elem.map(sliding_window))\n",
    "\n",
    "temp_ds = train_dataset.take(2).map(lambda ecg, label: sliding_window(ecg, label))\n",
    "# for elem in temp_ds:\n",
    "#     print(len(elem))\n",
    "    \n",
    "# print(type(elem))\n",
    "# print(len(elem))\n",
    "# print(elem[0])\n",
    "# print(elem[1])\n",
    "# print(x)\n",
    "    \n",
    "# train_dataset.map(sliding_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51a19370-24f5-48a4-90cf-f4b068b2097b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_length    = X_train[0].shape[1]\n",
    "sequence_length = 250\n",
    "sequence_stride = 50\n",
    "\n",
    "temp_ds = keras.utils.timeseries_dataset_from_array(data=X_test,\n",
    "                                                   targets=np.repeat(Y_test,(total_length-sequence_length)/sequence_stride),\n",
    "                                                   sequence_length=sequence_length,\n",
    "                                                   sequence_stride=sequence_stride,\n",
    "                                                   sampling_rate=1,\n",
    "                                                   batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b427f427-6694-4945-88a9-ef064274a847",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "window_ds = train_dataset.take(1).window(size=250, shift=50)\n",
    "window = next(iter(window_ds))\n",
    "for elem in window[0].as_numpy_iterator():\n",
    "    x = elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9c0ddc57-28e8-491e-a20f-86808e0d83c7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_30348/3721291042.py\", line 1, in None  *\n        lambda ecg, label: sliding_window((ecg, label))\n    File \"C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_30348/644226537.py\", line 15, in sliding_window  *\n        n_sequences = int((array.shape[1]-sequence_length)/sequence_stride)\n\n    AttributeError: 'tuple' object has no attribute 'shape'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_30348/3721291042.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_dataset_windows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mecg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msliding_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mecg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_dataset_windows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mecg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msliding_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mecg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[0;32m   2015\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[1;32m-> 2016\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2017\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5189\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5190\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5191\u001b[1;33m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   5192\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5193\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;31m# There is no graph to add in eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[1;33m&=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3068\u001b[0m          \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3069\u001b[0m     \"\"\"\n\u001b[1;32m-> 3070\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   3071\u001b[0m         *args, **kwargs)\n\u001b[0;32m   3072\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3034\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3035\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3036\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3037\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3038\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3292\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   3294\u001b[0m                                    graph_function)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3128\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3129\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3130\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3131\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3132\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    246\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m    247\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_30348/3721291042.py\", line 1, in None  *\n        lambda ecg, label: sliding_window((ecg, label))\n    File \"C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_30348/644226537.py\", line 15, in sliding_window  *\n        n_sequences = int((array.shape[1]-sequence_length)/sequence_stride)\n\n    AttributeError: 'tuple' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "train_dataset_windows = train_dataset.map(lambda ecg, label: sliding_window((ecg, label)))\n",
    "val_dataset_windows = val_dataset.map(lambda ecg, label: sliding_window((ecg, label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9eb057-42a1-4241-94fa-054ab06b7a90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Recrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f98a64c-33dd-4659-9844-9c888cfbb83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.043,  0.025, -0.01 , ...,  0.091,  0.494,  0.572],\n",
       "       [ 0.11 ,  0.072,  0.043, ...,  0.13 ,  0.338,  0.317],\n",
       "       [ 0.067,  0.047,  0.053, ...,  0.039, -0.156, -0.254],\n",
       "       ...,\n",
       "       [ 0.107,  0.089,  0.044, ...,  0.179,  0.495,  0.231],\n",
       "       [ 0.103,  0.077,  0.027, ...,  0.104,  0.415,  0.413],\n",
       "       [ 0.124,  0.088,  0.062, ..., -0.014,  0.23 ,  0.369]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_recrop(array, sequence_length=250):\n",
    "\n",
    "    array_length = array.shape[1]\n",
    "    start_idx = random.randint(0, array_length-sequence_length-1)\n",
    "    seq = array[:,start_idx:start_idx+sequence_length]\n",
    "\n",
    "    return seq\n",
    "\n",
    "array = x #X_train[0]\n",
    "sequence_length = 250\n",
    "sequence_stride = 50\n",
    "\n",
    "random_recrop(array, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26aecb88-174a-4780-89a8-49a67d03c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_dataset.take(1).as_numpy_iterator():\n",
    "    temp = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c71c0d6d-e942-4311-8403-c73497565a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = len(X_train)\n",
    "\n",
    "train_dataset_recrop = train_dataset.map(lambda x, y: (random_recrop(x), y)).shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "val_dataset_recrop = val_dataset.map(lambda x, y: (random_recrop(x), y)).batch(BATCH_SIZE)\n",
    "\n",
    "input_shape = (12, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a966ac-b49f-4f1a-a62d-6158abc9e185",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model 1: Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e258d9e-6e03-4482-92e5-77ad8fb47ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 250)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "261b0cd9-bd0e-4d58-a926-898bc4cd68a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", input_shape=input_shape),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "\n",
    "    keras.layers.GlobalAveragePooling1D(),\n",
    "\n",
    "    keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.build(input_shape)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be68c8c2-79de-44f7-a929-54126e4e4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69b88c7d-5d04-432f-8a2b-d6efa8a975cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "    869/Unknown - 1247s 1s/step - loss: 1.7514 - accuracy: 0.4934WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "869/869 [==============================] - 1247s 1s/step - loss: 1.7514 - accuracy: 0.4934 - lr: 0.0010\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_44416/3668450103.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m history = model.fit(train_ds,\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#                     validation_data=val_dataset_recrop,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\"),\n",
    "             keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001),\n",
    "             keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),]\n",
    "\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "#                     validation_data=val_dataset_recrop,\n",
    "                    epochs=epochs,\n",
    "#                     batch_size=batch_size,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f30ef6d5-d954-4818-a234-8b242d411445",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "463/463 [==============================] - 18s 27ms/step - loss: 1.7386 - accuracy: 0.5145 - val_loss: 1.6803 - val_accuracy: 0.5317 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "463/463 [==============================] - 12s 26ms/step - loss: 1.4288 - accuracy: 0.5831 - val_loss: 1.4921 - val_accuracy: 0.5482 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "463/463 [==============================] - 12s 25ms/step - loss: 1.3104 - accuracy: 0.6097 - val_loss: 1.3365 - val_accuracy: 0.6112 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "463/463 [==============================] - 12s 26ms/step - loss: 1.2401 - accuracy: 0.6288 - val_loss: 1.3336 - val_accuracy: 0.5914 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "463/463 [==============================] - 12s 25ms/step - loss: 1.1879 - accuracy: 0.6417 - val_loss: 1.2776 - val_accuracy: 0.6211 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "463/463 [==============================] - 12s 26ms/step - loss: 1.1568 - accuracy: 0.6505 - val_loss: 1.2451 - val_accuracy: 0.6206 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "463/463 [==============================] - 12s 26ms/step - loss: 1.1261 - accuracy: 0.6587 - val_loss: 1.2524 - val_accuracy: 0.6152 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "463/463 [==============================] - 12s 26ms/step - loss: 1.1096 - accuracy: 0.6611 - val_loss: 1.2214 - val_accuracy: 0.6267 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "463/463 [==============================] - 12s 26ms/step - loss: 1.0838 - accuracy: 0.6707 - val_loss: 1.2394 - val_accuracy: 0.6303 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "463/463 [==============================] - 12s 25ms/step - loss: 1.0675 - accuracy: 0.6702 - val_loss: 1.2417 - val_accuracy: 0.6298 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "463/463 [==============================] - 12s 26ms/step - loss: 1.0525 - accuracy: 0.6748 - val_loss: 1.2065 - val_accuracy: 0.6333 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "463/463 [==============================] - 13s 27ms/step - loss: 1.0424 - accuracy: 0.6756 - val_loss: 1.1571 - val_accuracy: 0.6423 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "463/463 [==============================] - 12s 27ms/step - loss: 1.0234 - accuracy: 0.6827 - val_loss: 1.2517 - val_accuracy: 0.6253 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "463/463 [==============================] - 12s 27ms/step - loss: 1.0178 - accuracy: 0.6875 - val_loss: 1.1698 - val_accuracy: 0.6362 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "463/463 [==============================] - 12s 25ms/step - loss: 1.0103 - accuracy: 0.6877 - val_loss: 1.1660 - val_accuracy: 0.6527 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\"),\n",
    "             keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001),\n",
    "             keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),]\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=epochs,\n",
    "#                     batch_size=batch_size,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c72b735-e3ce-4f45-8ad9-76888bc5ffd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "463/463 [==============================] - 12s 21ms/step - loss: 2.0273 - accuracy: 0.4395 - val_loss: 1.9192 - val_accuracy: 0.4551 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "463/463 [==============================] - 11s 22ms/step - loss: 1.7591 - accuracy: 0.4868 - val_loss: 1.8674 - val_accuracy: 0.4624 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "463/463 [==============================] - 10s 21ms/step - loss: 1.6453 - accuracy: 0.5135 - val_loss: 1.8349 - val_accuracy: 0.4827 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "463/463 [==============================] - 10s 22ms/step - loss: 1.5395 - accuracy: 0.5448 - val_loss: 1.8403 - val_accuracy: 0.4735 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "463/463 [==============================] - 9s 19ms/step - loss: 1.4533 - accuracy: 0.5651 - val_loss: 1.8895 - val_accuracy: 0.4633 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "463/463 [==============================] - 9s 19ms/step - loss: 1.3665 - accuracy: 0.5900 - val_loss: 1.9099 - val_accuracy: 0.4589 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "463/463 [==============================] - 9s 19ms/step - loss: 1.2834 - accuracy: 0.6108 - val_loss: 1.9653 - val_accuracy: 0.4482 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "463/463 [==============================] - 9s 19ms/step - loss: 1.2085 - accuracy: 0.6345 - val_loss: 1.9800 - val_accuracy: 0.4676 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "463/463 [==============================] - 9s 19ms/step - loss: 1.1460 - accuracy: 0.6513 - val_loss: 2.0816 - val_accuracy: 0.4296 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "463/463 [==============================] - 9s 19ms/step - loss: 1.0735 - accuracy: 0.6723 - val_loss: 2.0823 - val_accuracy: 0.4362 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "463/463 [==============================] - 9s 19ms/step - loss: 1.0164 - accuracy: 0.6901 - val_loss: 2.1830 - val_accuracy: 0.4431 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "463/463 [==============================] - 9s 20ms/step - loss: 0.9556 - accuracy: 0.7077 - val_loss: 2.2676 - val_accuracy: 0.4440 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "463/463 [==============================] - 10s 20ms/step - loss: 0.8983 - accuracy: 0.7258 - val_loss: 2.5226 - val_accuracy: 0.3931 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "463/463 [==============================] - 9s 19ms/step - loss: 0.8528 - accuracy: 0.7375 - val_loss: 2.4014 - val_accuracy: 0.4303 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "463/463 [==============================] - 9s 19ms/step - loss: 0.7993 - accuracy: 0.7524 - val_loss: 2.4426 - val_accuracy: 0.4395 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\"),\n",
    "             keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001),\n",
    "             keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),]\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset_recrop,\n",
    "                    validation_data=val_dataset_recrop,\n",
    "                    epochs=epochs,\n",
    "#                     batch_size=batch_size,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "958d9ecd-f714-4ae3-b043-c0977c9c39e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2138/2138 [==============================] - 11s 5ms/step - loss: 1.2009 - accuracy: 0.6408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2008675336837769, 0.6407857537269592]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = keras.models.load_model('best_model.h5')\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97dff38-5fba-44db-a049-c7cf4a1a91ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model 2: Resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731d02fb-d770-449c-9e75-8a941ca5cea7",
   "metadata": {
    "tags": []
   },
   "source": [
    "when tuning start with learning rate->mini_batch_size -> momentum-> #hidden_units -> # learning_rate_decay -> #layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d71b5652-dc77-4c6f-83d6-e2b505485335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet1d(input_shape, nb_classes):\n",
    "    \n",
    "    n_feature_maps = 64\n",
    "\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    # BLOCK 1\n",
    "    conv_x = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(input_layer)\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "    conv_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "    conv_z = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y)\n",
    "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "    # expand channels for the sum\n",
    "    shortcut_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(input_layer)\n",
    "    shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "    output_block_1 = keras.layers.add([shortcut_y, conv_z])\n",
    "    output_block_1 = keras.layers.Activation('relu')(output_block_1)\n",
    "    # insert droupout layer\n",
    "\n",
    "    \n",
    "    # BLOCK 2\n",
    "    conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(output_block_1)\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "    conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "    conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "    # expand channels for the sum\n",
    "    shortcut_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n",
    "    shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "    output_block_2 = keras.layers.add([shortcut_y, conv_z])\n",
    "    output_block_2 = keras.layers.Activation('relu')(output_block_2)\n",
    "    # insert droupout layer\n",
    "\n",
    "    \n",
    "    # BLOCK 3\n",
    "    conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(output_block_2)\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "    conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "    conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "    # no need to expand channels because they are equal\n",
    "    shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n",
    "\n",
    "    output_block_3 = keras.layers.add([shortcut_y, conv_z])\n",
    "    output_block_3 = keras.layers.Activation('relu')(output_block_3)\n",
    "    \n",
    "    # insert droupout layer\n",
    "\n",
    "    \n",
    "    # FINAL\n",
    "    gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n",
    "    \n",
    "    # insert droupout layer\n",
    "\n",
    "    output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d41de5-d418-4e9f-8a69-07982721671a",
   "metadata": {},
   "source": [
    "to help with overfitting (a generalizability problem):\n",
    "- windows, increases data size\n",
    "- add dropout layers\n",
    "- augmentations: add random noise\n",
    "\n",
    "\n",
    "try standardizing? won't necessarily help with overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cb4a9fc-ac23-42b8-857d-cdde98c20eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 12, 1000)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 12, 64)       192064      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 12, 64)      256         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 12, 64)       0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 12, 64)       12352       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 12, 64)      256         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 12, 64)       0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 12, 64)       64064       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 12, 64)       12352       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 12, 64)      256         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 12, 64)      256         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 12, 64)       0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 12, 64)       0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 12, 128)      24704       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 12, 128)     512         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 12, 128)      0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 12, 128)      49280       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 12, 128)     512         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 12, 128)      0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 12, 128)      8320        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 12, 128)      49280       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 12, 128)     512         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 12, 128)     512         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 12, 128)      0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 12, 128)      0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 12, 128)      49280       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 12, 128)     512         ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 12, 128)      0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 12, 128)      49280       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 12, 128)     512         ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 12, 128)      0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 12, 128)      49280       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 12, 128)     512         ['activation_5[0][0]']           \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 12, 128)     512         ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 12, 128)      0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 12, 128)      0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['activation_8[0][0]']           \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 23)           2967        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 568,343\n",
      "Trainable params: 565,783\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = resnet1d(input_shape = input_shape,\n",
    "                 nb_classes = num_classes)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95ed07c9-7a67-4161-88bd-ef0db1cfa753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "463/463 [==============================] - 27s 38ms/step - loss: 2.0161 - accuracy: 0.4417 - val_loss: 2.0684 - val_accuracy: 0.4530 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "463/463 [==============================] - 17s 36ms/step - loss: 1.7190 - accuracy: 0.4960 - val_loss: 1.9722 - val_accuracy: 0.4589 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "463/463 [==============================] - 17s 36ms/step - loss: 1.4807 - accuracy: 0.5595 - val_loss: 1.9561 - val_accuracy: 0.4548 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "463/463 [==============================] - 16s 36ms/step - loss: 1.2079 - accuracy: 0.6375 - val_loss: 2.1000 - val_accuracy: 0.4240 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "463/463 [==============================] - 16s 35ms/step - loss: 0.9429 - accuracy: 0.7130 - val_loss: 2.3132 - val_accuracy: 0.4079 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "463/463 [==============================] - 17s 36ms/step - loss: 0.7176 - accuracy: 0.7824 - val_loss: 2.7267 - val_accuracy: 0.3954 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "463/463 [==============================] - 16s 35ms/step - loss: 0.5375 - accuracy: 0.8377 - val_loss: 3.1425 - val_accuracy: 0.3787 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "463/463 [==============================] - 17s 36ms/step - loss: 0.4187 - accuracy: 0.8715 - val_loss: 3.2361 - val_accuracy: 0.4141 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "463/463 [==============================] - 17s 36ms/step - loss: 0.3296 - accuracy: 0.8989 - val_loss: 3.5317 - val_accuracy: 0.4011 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "463/463 [==============================] - 17s 36ms/step - loss: 0.2582 - accuracy: 0.9181 - val_loss: 3.9026 - val_accuracy: 0.3638 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "463/463 [==============================] - 16s 35ms/step - loss: 0.2320 - accuracy: 0.9291 - val_loss: 3.8458 - val_accuracy: 0.4145 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "463/463 [==============================] - 16s 35ms/step - loss: 0.1947 - accuracy: 0.9387 - val_loss: 3.9882 - val_accuracy: 0.4228 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "463/463 [==============================] - 17s 36ms/step - loss: 0.1950 - accuracy: 0.9384 - val_loss: 4.1365 - val_accuracy: 0.3975 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "463/463 [==============================] - 16s 35ms/step - loss: 0.1512 - accuracy: 0.9506 - val_loss: 4.2571 - val_accuracy: 0.3940 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "463/463 [==============================] - 16s 35ms/step - loss: 0.1399 - accuracy: 0.9549 - val_loss: 4.2997 - val_accuracy: 0.3905 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"resnet_model.h5\", save_best_only=True, monitor=\"val_loss\"),\n",
    "             keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001),\n",
    "             keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),]\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=epochs,\n",
    "                  # batch_size=batch_size,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "23f4b6e2-3ce7-4586-b02e-e1eb02d2fd5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "463/463 [==============================] - 23s 41ms/step - loss: 1.9944 - accuracy: 0.4418 - val_loss: 1.9357 - val_accuracy: 0.4572 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "463/463 [==============================] - 19s 40ms/step - loss: 1.6913 - accuracy: 0.5018 - val_loss: 1.8578 - val_accuracy: 0.4777 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "463/463 [==============================] - 19s 41ms/step - loss: 1.5238 - accuracy: 0.5421 - val_loss: 1.7408 - val_accuracy: 0.4808 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "463/463 [==============================] - 19s 40ms/step - loss: 1.3623 - accuracy: 0.5883 - val_loss: 1.7952 - val_accuracy: 0.4968 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "463/463 [==============================] - 18s 39ms/step - loss: 1.2238 - accuracy: 0.6283 - val_loss: 1.8533 - val_accuracy: 0.4617 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "463/463 [==============================] - 18s 39ms/step - loss: 1.0891 - accuracy: 0.6655 - val_loss: 1.8807 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "463/463 [==============================] - 20s 42ms/step - loss: 0.9437 - accuracy: 0.7063 - val_loss: 2.0845 - val_accuracy: 0.4796 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "463/463 [==============================] - 20s 42ms/step - loss: 0.8202 - accuracy: 0.7465 - val_loss: 2.1801 - val_accuracy: 0.4591 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "463/463 [==============================] - 20s 41ms/step - loss: 0.7136 - accuracy: 0.7769 - val_loss: 2.2945 - val_accuracy: 0.4579 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "463/463 [==============================] - 19s 41ms/step - loss: 0.5875 - accuracy: 0.8139 - val_loss: 2.5200 - val_accuracy: 0.4395 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "463/463 [==============================] - 20s 42ms/step - loss: 0.5048 - accuracy: 0.8392 - val_loss: 2.7279 - val_accuracy: 0.4329 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "463/463 [==============================] - 19s 40ms/step - loss: 0.4325 - accuracy: 0.8641 - val_loss: 2.8180 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "463/463 [==============================] - 18s 38ms/step - loss: 0.3727 - accuracy: 0.8799 - val_loss: 2.9724 - val_accuracy: 0.4492 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "463/463 [==============================] - 19s 39ms/step - loss: 0.3139 - accuracy: 0.8977 - val_loss: 3.0456 - val_accuracy: 0.4258 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "463/463 [==============================] - 20s 41ms/step - loss: 0.2952 - accuracy: 0.9007 - val_loss: 3.3438 - val_accuracy: 0.4174 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Recropped model\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"resnet_model.h5\", save_best_only=True, monitor=\"val_loss\"),\n",
    "             keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001),\n",
    "             keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),]\n",
    "\n",
    "history = model.fit(train_dataset_recrop,\n",
    "                    validation_data=val_dataset_recrop,\n",
    "                    epochs=epochs,\n",
    "#                     batch_size=batch_size,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
